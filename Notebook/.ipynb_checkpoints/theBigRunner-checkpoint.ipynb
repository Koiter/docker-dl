{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3303 images belonging to 5 classes.\n",
      "Found 367 images belonging to 5 classes.\n",
      "Image batch shape:  (32, 32, 32, 3)\n",
      "Label batch shape:  (32, 5)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tf.VERSION\n",
    "\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "train_data = image_generator.flow_from_directory(\"flower_photos\",target_size=(32,32))\n",
    "validation_data = image_generator.flow_from_directory(\"flower_photos_test\",target_size=(32,32))\n",
    "\n",
    "for image_batch,label_batch in train_data:\n",
    "  print(\"Image batch shape: \", image_batch.shape)\n",
    "  print(\"Label batch shape: \", label_batch.shape)\n",
    "  break\n",
    "\n",
    "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
    "  def __init__(self):\n",
    "    self.batch_losses = []\n",
    "    self.batch_acc = []\n",
    "    self.epoch_val_loss = []\n",
    "    self.epoch_val_acc = []\n",
    "    \n",
    "  def on_batch_end(self, batch, logs=None):\n",
    "    self.batch_losses.append(logs['loss'])\n",
    "    self.batch_acc.append(logs['acc'])\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    self.epoch_val_loss.append(logs['val_loss'])\n",
    "    self.epoch_val_acc.append(logs['val_acc'])\n",
    "\n",
    "runs = [2, 3]\n",
    "activation = [0, 0, 1, 1, 2, 2]\n",
    "lossF = ['categorical_crossentropy', 'mean_squared_error', 'categorical_crossentropy', 'mean_squared_error', 'categorical_crossentropy', 'mean_squared_error']\n",
    "saveName = ['Tanh', 'MSETanh', 'RELU', 'MSERELU', 'LeakyRELU', 'MSELeakyRELU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in runs:\n",
    "    model = None\n",
    "    if (activation[id] == 0):\n",
    "        # CNN 2\n",
    "        model = tf.keras.Sequential([\n",
    "          layers.Conv2D(32, [3, 3], (1, 1), 'valid', input_shape=(image_batch.shape[1], image_batch.shape[2], image_batch.shape[3])),\n",
    "          layers.Activation('tanh'),\n",
    "          # layers.LeakyReLU(alpha=0.3),\n",
    "          layers.MaxPooling2D(pool_size=(2 , 2)),\n",
    "\n",
    "          layers.Conv2D(64, [3, 3], (1, 1), 'valid'),\n",
    "          layers.Activation('tanh'),\n",
    "          # layers.LeakyReLU(alpha=0.3),\n",
    "          layers.MaxPooling2D(pool_size=(2 , 2)),\n",
    "\n",
    "          layers.Conv2D(128, [3, 3], (1, 1), 'valid'),\n",
    "          layers.Activation('tanh'),\n",
    "          # layers.LeakyReLU(alpha=0.3),\n",
    "          layers.Flatten(),\n",
    "\n",
    "          layers.Dense(train_data.num_classes, activation='softmax')\n",
    "        ])\n",
    "    if (activation[id] == 1):\n",
    "        # CNN 2\n",
    "        model = tf.keras.Sequential([\n",
    "          layers.Conv2D(32, [3, 3], (1, 1), 'valid', input_shape=(image_batch.shape[1], image_batch.shape[2], image_batch.shape[3])),\n",
    "          layers.Activation('relu'),\n",
    "          # layers.LeakyReLU(alpha=0.3),\n",
    "          layers.MaxPooling2D(pool_size=(2 , 2)),\n",
    "\n",
    "          layers.Conv2D(64, [3, 3], (1, 1), 'valid'),\n",
    "          layers.Activation('relu'),\n",
    "          # layers.LeakyReLU(alpha=0.3),\n",
    "          layers.MaxPooling2D(pool_size=(2 , 2)),\n",
    "\n",
    "          layers.Conv2D(128, [3, 3], (1, 1), 'valid'),\n",
    "          layers.Activation('relu'),\n",
    "          # layers.LeakyReLU(alpha=0.3),\n",
    "          layers.Flatten(),\n",
    "\n",
    "          layers.Dense(train_data.num_classes, activation='softmax')\n",
    "        ])\n",
    "    if (activation[id] == 2):\n",
    "        # CNN 2\n",
    "        model = tf.keras.Sequential([\n",
    "          layers.Conv2D(32, [3, 3], (1, 1), 'valid', input_shape=(image_batch.shape[1], image_batch.shape[2], image_batch.shape[3])),\n",
    "          # layers.Activation('relu'),\n",
    "          layers.LeakyReLU(alpha=0.3),\n",
    "          layers.MaxPooling2D(pool_size=(2 , 2)),\n",
    "\n",
    "          layers.Conv2D(64, [3, 3], (1, 1), 'valid'),\n",
    "          # layers.Activation('relu'),\n",
    "          layers.LeakyReLU(alpha=0.3),\n",
    "          layers.MaxPooling2D(pool_size=(2 , 2)),\n",
    "\n",
    "          layers.Conv2D(128, [3, 3], (1, 1), 'valid'),\n",
    "          # layers.Activation('relu'),\n",
    "          layers.LeakyReLU(alpha=0.3),\n",
    "          layers.Flatten(),\n",
    "\n",
    "          layers.Dense(train_data.num_classes, activation='softmax')\n",
    "        ])\n",
    "    model.compile(\n",
    "        optimizer=tf.train.AdamOptimizer(), \n",
    "        loss=lossF[id],\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    batch_stats = CollectBatchStats()\n",
    "    model.fit_generator(train_data, epochs=4, \n",
    "        callbacks = [batch_stats],\n",
    "        validation_data = validation_data)\n",
    "    \n",
    "    results = pd.DataFrame({\"losses\":batch_stats.batch_losses, \"accuracy\":batch_stats.batch_acc})\n",
    "    results.to_csv(\"saved_results/cnn\"+saveName[id]+\"Data.csv\", ',')\n",
    "    results = pd.DataFrame({\"losses\":batch_stats.epoch_val_loss, \"accuracy\":batch_stats.epoch_val_acc})\n",
    "    results.to_csv(\"saved_results/cnn\"+saveName[id]+\"ValData.csv\", ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-ce281ab9e58a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "categories = len(np.unique(data.y_train))\n",
    "processed_data = preprocess(data, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3303 images belonging to 5 classes.\n",
      "Found 367 images belonging to 5 classes.\n",
      "Image batch shape:  (32, 32, 32, 1)\n",
      "Label batch shape:  (32, 5)\n",
      "This is run: 1\n",
      "\n",
      " \n",
      "\n",
      "Image size: 32 * 32\n",
      "Loss function: mean_squared_error\n",
      "Activation function: softmax\n",
      "Epoch 1/15\n",
      " 94/104 [==========================>...] - ETA: 1s - loss: 0.1597 - acc: 0.2400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-26eb73792da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_stats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                            )\n\u001b[1;32m     73\u001b[0m             \u001b[0msavedMods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimSizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactFunc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFunc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;31m# Legacy support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "actFunc = ['softmax','relu','leaky','tanh']\n",
    "lossFunc = ['mean_squared_error','categorical_crossentropy']\n",
    "imSizes = [32,64]\n",
    "\n",
    "def getData(size):\n",
    "    t_data = image_generator.flow_from_directory(\"flower_photos\",color_mode=\"grayscale\",target_size=(size,size))\n",
    "    v_data = image_generator.flow_from_directory(\"flower_photos_test\",color_mode=\"grayscale\",target_size=(size,size))\n",
    "    return t_data, v_data\n",
    "\n",
    "def plainVanilla(images, labels, activ, los):\n",
    "    #print (images.shape[1], images.shape[2], images.shape[3])\n",
    "    if actFunc[k] == 'leaky':\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Flatten(input_shape=(images.shape[1], images.shape[2], images.shape[3])),\n",
    "            layers.Dense(1024),\n",
    "            layers.LeakyReLU(alpha=0.3),\n",
    "            layers.Dense(512),\n",
    "            layers.LeakyReLU(alpha=0.3),\n",
    "            layers.Dense(labels, activation='softmax')\n",
    "        ])\n",
    "    else:\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Flatten(input_shape=(images.shape[1], images.shape[2], images.shape[3])),\n",
    "            layers.Dense(1024, activation=activ),\n",
    "            #layers.Dropout(0.2),\n",
    "            layers.Dense(512, activation=activ),\n",
    "            #layers.Dropout(0.2),\n",
    "            layers.Dense(labels, activation='softmax')\n",
    "        ])\n",
    "    model.compile(\n",
    "        optimizer=tf.train.AdamOptimizer(), \n",
    "        loss=los,\n",
    "        metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def trainModel(model, tr_dat, val_dat):\n",
    "    batch_stats = CollectBatchStats()\n",
    "    model.fit_generator(tr_dat, epochs=epoch, \n",
    "        callbacks = [batch_stats],         \n",
    "        validation_data = val_dat)\n",
    "    return callbacks\n",
    "\n",
    "    \n",
    "\n",
    "#initialisation\n",
    "epoch = 15\n",
    "\n",
    "savedMods = []\n",
    "runs = 1\n",
    "for i in range((len(imSizes)-1)):\n",
    "    train_dat, validation_dat = getData(imSizes[i])\n",
    "    \n",
    "    for image_batch,label_batch in train_dat:\n",
    "        print(\"Image batch shape: \", image_batch.shape)\n",
    "        print(\"Label batch shape: \", label_batch.shape)\n",
    "        break\n",
    "    \n",
    "    for j in range(len(lossFunc)-1):\n",
    "        for k in range(len(actFunc)-1):\n",
    "            print ('This is run: '+ str(runs))\n",
    "            print ('\\n \\n')\n",
    "            print ('Image size: '+ str(imSizes[i]) + ' * ' + str(imSizes[i]))\n",
    "            print ('Loss function: '+lossFunc[j])\n",
    "            print ('Activation function: '+actFunc[k])\n",
    "            print ( '\\n')\n",
    "            model = plainVanilla(image_batch, train_dat.num_classes, actFunc[k], lossFunc[j])\n",
    "            batch_stats = CollectBatchStats()\n",
    "            mod = model.fit(train_dat,\n",
    "                            epochs=epoch, \n",
    "                            validation_data=validation_dat,\n",
    "                            callbacks=[batch_stats]\n",
    "                           )\n",
    "            savedMods.append([imSizes[i], actFunc[k], lossFunc[j], mod])\n",
    "            runs += 1\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['roses', 'sunflowers', 'daisy', 'dandelion', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "# pak van elke soort een plaatje\n",
    "soorten = os.listdir('flower_photos')[0:5]\n",
    "simg = []\n",
    "for n in range(5):\n",
    "    simg.append(Image('flower_photos/'+soorten[n]+'/'+os.listdir('flower_photos/'+soorten[n])[5]))\n",
    "print(soorten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n",
    "len(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3303 images belonging to 5 classes.\n",
      "Found 367 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
    "train_data = image_generator.flow_from_directory(\"flower_photos\",target_size=(32,32))\n",
    "validation_data = image_generator.flow_from_directory(\"flower_photos_test\",target_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(imSizes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
